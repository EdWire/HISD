{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Learning Analytics v2\r\n",
        "\r\n",
        "## Learning Resources Schema Dimension Tables\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run OEA_py"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": "47",
              "statement_id": -1,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-07-10T18:47:44.3778012Z",
              "session_start_time": null,
              "execution_start_time": "2023-07-10T18:47:55.7305564Z",
              "execution_finish_time": "2023-07-10T18:47:55.7308327Z",
              "spark_jobs": null,
              "parent_msg_id": "3c7205c7-c6eb-480d-bda6-333792086fe5"
            },
            "text/plain": "StatementMeta(, 47, -1, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-10 18:47:53,879 - OEA - INFO - Now using workspace: dev\n2023-07-10 18:47:53,880 - OEA - INFO - OEA initialized.\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "workspace = 'dev'\r\n",
        "oea.set_workspace(workspace)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "47",
              "statement_id": 4,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-07-10T18:48:07.76559Z",
              "session_start_time": null,
              "execution_start_time": "2023-07-10T18:48:07.9241317Z",
              "execution_finish_time": "2023-07-10T18:48:08.1160215Z",
              "spark_jobs": null,
              "parent_msg_id": "1f3ef04f-d2c7-4841-83b7-35c1cad1d150"
            },
            "text/plain": "StatementMeta(spark3p3sm, 47, 4, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-10 18:48:07,887 - OEA - INFO - Now using workspace: dev\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, lit, split\r\n",
        "from pyspark.sql import functions as f\r\n",
        "import os\r\n",
        "import uuid\r\n",
        "\r\n",
        "# helper functions\r\n",
        "def _publish_to_stage2(df, destination, pk):\r\n",
        "    oea.upsert(df, destination, pk)\r\n",
        "\r\n",
        "def publish(df, stage2_destination, stage3_destination, primary_key='id'):\r\n",
        "    _publish_to_stage2(df, stage2_destination, primary_key)\r\n",
        "\r\n",
        "    spark.sql(\"set spark.sql.streaming.schemaInference=true\")\r\n",
        "    streaming_df = spark.readStream.format('delta').load(oea.to_url(stage2_destination))\r\n",
        "    # for more info on append vs complete vs update modes for structured streaming: https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#basic-concepts\r\n",
        "    query = streaming_df.writeStream.format('delta').outputMode('append').trigger(once=True).option('checkpointLocation', oea.to_url(stage2_destination) + '/_checkpoints')\r\n",
        "    query = query.start(oea.to_url(stage3_destination))\r\n",
        "    query.awaitTermination()   # block until query is terminated, with stop() or with error; A StreamingQueryException will be thrown if an exception occurs.\r\n",
        "    number_of_new_inbound_rows = query.lastProgress[\"numInputRows\"]\r\n",
        "    logger.info(f'Number of new inbound rows processed: {number_of_new_inbound_rows}')\r\n",
        "    logger.debug(query.lastProgress)\r\n",
        "    return number_of_new_inbound_rows\r\n",
        "\r\n",
        "def format_to_schema(df, column_mapping, schema, source_directory):\r\n",
        "    \"\"\" This function formats a dataframe to match a schema dataframe format. \r\n",
        "        Column mapping needs to be provided. If columns are missing, they are filled as none type.\r\n",
        "    \"\"\"\r\n",
        "    \r\n",
        "    # rename columns\r\n",
        "    dfSource = df.select([col(existing_col).alias(column_mapping[existing_col]) for existing_col in df.columns])\r\n",
        "    data_source = source_directory.split(os.path.sep)[2]\r\n",
        "    dfSource = dfSource.withColumn(\"data_source\", lit(data_source))\r\n",
        "    dfSource = dfSource.withColumn(\"source_directory\", lit(source_directory)) \r\n",
        "\r\n",
        "    # create missing columns with needed data type\r\n",
        "    missing_columns = [col for col in schema.names if col not in dfSource.columns]\r\n",
        "    for column in missing_columns:\r\n",
        "        dfSource = dfSource.withColumn(column, lit(None).cast(schema[column].dataType))\r\n",
        "\r\n",
        "    dfSource = dfSource.select(schema.names) # ensure column order matches\r\n",
        "\r\n",
        "    return dfSource"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "47",
              "statement_id": 5,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-07-10T18:48:17.6334212Z",
              "session_start_time": null,
              "execution_start_time": "2023-07-10T18:48:17.7739225Z",
              "execution_finish_time": "2023-07-10T18:48:17.9484783Z",
              "spark_jobs": null,
              "parent_msg_id": "175cd388-94eb-4a0f-829e-86c093a8c300"
            },
            "text/plain": "StatementMeta(spark3p3sm, 47, 5, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# map instructor id to SIS course id\r\n",
        "assign_directory = 'stage2/Refined/moodle/v4.1/general/assign'\r\n",
        "assigngrades_directory = 'stage2/Refined/moodle/v4.1/general/assign_grades'\r\n",
        "dfAssignment = oea.load(assign_directory)\r\n",
        "dfAssignment = dfAssignment.select(['id', 'course'])\r\n",
        "dfAsGrades = oea.load(assigngrades_directory)\r\n",
        "dfAsGrades = dfAsGrades.select(['assignment', 'grader_pseudonym'])\r\n",
        "dfAsGrades = dfAsGrades.withColumnRenamed(\"assignment\", \"id\")\r\n",
        "dfInstructor = dfAssignment.join(dfAsGrades, \"id\")\r\n",
        "dfInstructor = dfInstructor.drop_duplicates()\r\n",
        "dfInstructor = dfInstructor.drop(\"id\")\r\n",
        "\r\n",
        "source_directory = 'stage2/Refined/moodle/v4.1/general/course'\r\n",
        "dfCourse = oea.load(source_directory)\r\n",
        "dfCourse = dfCourse.select(['id','category'])\r\n",
        "dfCourse = dfCourse.withColumnRenamed(\"id\", \"course\")\r\n",
        "dfInstructor = dfInstructor.join(dfCourse, \"course\")\r\n",
        "dfInstructor = dfInstructor.drop(\"course\")\r\n",
        "\r\n",
        "# dfInstructor is now a dataframe containing two columns, grader_pseudonym and category"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "47",
              "statement_id": 6,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-07-10T18:48:32.2958296Z",
              "session_start_time": null,
              "execution_start_time": "2023-07-10T18:48:32.4474363Z",
              "execution_finish_time": "2023-07-10T18:49:08.1547142Z",
              "spark_jobs": null,
              "parent_msg_id": "62984436-6615-488b-911c-89dd1924109b"
            },
            "text/plain": "StatementMeta(spark3p3sm, 47, 6, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create dim schema\r\n",
        "column_names = ['id', 'course_id', 'instructor_id', 'source_resource_id', 'resource_type', 'name', 'time_open', 'time_close',\r\n",
        "                   'data_source', 'source_directory']\r\n",
        "schema = StructType([StructField(name, StringType(), nullable=True) for name in column_names])\r\n",
        "dfDimResource = spark.createDataFrame([], schema)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "47",
              "statement_id": 7,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-07-10T18:50:01.6077644Z",
              "session_start_time": null,
              "execution_start_time": "2023-07-10T18:50:01.7591385Z",
              "execution_finish_time": "2023-07-10T18:50:01.9428127Z",
              "spark_jobs": null,
              "parent_msg_id": "42e07ed1-d24e-41c9-8d95-1fb77ad99ebd"
            },
            "text/plain": "StatementMeta(spark3p3sm, 47, 7, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# moodle quiz learning resource data\r\n",
        "source_directory = 'stage2/Refined/moodle/v4.1/general/quiz'\r\n",
        "dfQuiz = oea.load(source_directory)\r\n",
        "dfQuiz = dfQuiz.select(['id','course','name','timeopen','timeclose'])\r\n",
        "\r\n",
        "# map course id to SIS course id\r\n",
        "source_directory = 'stage2/Refined/moodle/v4.1/general/course'\r\n",
        "dfCourse = oea.load(source_directory)\r\n",
        "dfCourse = dfCourse.select(['id','category'])\r\n",
        "dfCourse = dfCourse.withColumnRenamed(\"id\", \"course\")\r\n",
        "dfQuiz = dfQuiz.join(dfCourse, \"course\")\r\n",
        "dfQuiz = dfQuiz.drop(\"course\")\r\n",
        "\r\n",
        "# get instructor id\r\n",
        "dfQuiz = dfQuiz.join(dfInstructor, \"category\")\r\n",
        "\r\n",
        "column_mapping = {'id': 'source_resource_id', 'category': 'course_id', 'grader_pseudonym': 'instructor_id', 'name': 'name', 'timeopen': 'time_open', \r\n",
        "                'timeclose': 'time_close'}\r\n",
        "dfSource = format_to_schema(dfQuiz, column_mapping, dfDimResource.schema, source_directory)           \r\n",
        "\r\n",
        "dfSource = dfSource.withColumn(\"resource_type\", lit(\"quiz\"))\r\n",
        "dfSource = dfSource.select(dfDimResource.columns) # ensure column order matches\r\n",
        "\r\n",
        "dfDimResource = dfDimResource.union(dfSource)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "47",
              "statement_id": 8,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-07-10T18:50:09.4132154Z",
              "session_start_time": null,
              "execution_start_time": "2023-07-10T18:50:09.5511297Z",
              "execution_finish_time": "2023-07-10T18:50:12.4331223Z",
              "spark_jobs": null,
              "parent_msg_id": "5ba5a538-5288-4eb8-8659-91a15655af14"
            },
            "text/plain": "StatementMeta(spark3p3sm, 47, 8, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# moodle assignment learning resource data\r\n",
        "source_directory = 'stage2/Refined/moodle/v4.1/general/assign'\r\n",
        "dfAssgn = oea.load(source_directory)\r\n",
        "dfAssgn = dfAssgn.select(['id','course','name','allowsubmissionsfromdate','duedate'])\r\n",
        "\r\n",
        "# map course id to SIS course id\r\n",
        "source_directory = 'stage2/Refined/moodle/v4.1/general/course'\r\n",
        "dfCourse = oea.load(source_directory)\r\n",
        "dfCourse = dfCourse.select(['id','category'])\r\n",
        "dfCourse = dfCourse.withColumnRenamed(\"id\", \"course\")\r\n",
        "dfAssgn = dfAssgn.join(dfCourse, \"course\")\r\n",
        "dfAssgn = dfAssgn.drop(\"course\")\r\n",
        "\r\n",
        "# get instructor id\r\n",
        "dfAssgn = dfAssgn.join(dfInstructor, \"category\")\r\n",
        "\r\n",
        "column_mapping = {'id': 'source_resource_id', 'category': 'course_id', 'grader_pseudonym': 'instructor_id', 'name': 'name', 'allowsubmissionsfromdate': 'time_open', \r\n",
        "                'duedate': 'time_close'}\r\n",
        "dfSource = format_to_schema(dfAssgn, column_mapping, dfDimResource.schema, source_directory)           \r\n",
        "\r\n",
        "dfSource = dfSource.withColumn(\"resource_type\", lit(\"assignment\"))\r\n",
        "dfSource = dfSource.select(dfDimResource.columns) # ensure column order matches\r\n",
        "\r\n",
        "dfDimResource = dfDimResource.union(dfSource)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "47",
              "statement_id": 9,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-07-10T18:50:17.2047326Z",
              "session_start_time": null,
              "execution_start_time": "2023-07-10T18:50:17.3518052Z",
              "execution_finish_time": "2023-07-10T18:50:17.9055661Z",
              "spark_jobs": null,
              "parent_msg_id": "16a7b96b-f119-4ffc-b3c3-d4038a62da9a"
            },
            "text/plain": "StatementMeta(spark3p3sm, 47, 9, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# moodle lesson learning resource data\r\n",
        "source_directory = 'stage2/Refined/moodle/v4.1/general/lesson'\r\n",
        "dfLesson = oea.load(source_directory)\r\n",
        "dfLesson = dfLesson.select(['id','course','name','available','deadline'])\r\n",
        "\r\n",
        "# map course id to SIS course id\r\n",
        "source_directory = 'stage2/Refined/moodle/v4.1/general/course'\r\n",
        "dfCourse = oea.load(source_directory)\r\n",
        "dfCourse = dfCourse.select(['id','category'])\r\n",
        "dfCourse = dfCourse.withColumnRenamed(\"id\", \"course\")\r\n",
        "dfLesson = dfLesson.join(dfCourse, \"course\")\r\n",
        "dfLesson = dfLesson.drop(\"course\")\r\n",
        "\r\n",
        "# get instructor id\r\n",
        "dfLesson = dfLesson.join(dfInstructor, \"category\")\r\n",
        "\r\n",
        "column_mapping = {'id': 'source_resource_id', 'category': 'course_id','grader_pseudonym': 'instructor_id', 'name': 'name', 'available': 'time_open', \r\n",
        "                'deadline': 'time_close'}\r\n",
        "dfSource = format_to_schema(dfLesson, column_mapping, dfDimResource.schema, source_directory)           \r\n",
        "\r\n",
        "dfSource = dfSource.withColumn(\"resource_type\", lit(\"lesson\"))\r\n",
        "dfSource = dfSource.select(dfDimResource.columns) # ensure column order matches\r\n",
        "\r\n",
        "dfDimResource = dfDimResource.union(dfSource)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "47",
              "statement_id": 10,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-07-10T18:52:31.4884135Z",
              "session_start_time": null,
              "execution_start_time": "2023-07-10T18:52:31.6552695Z",
              "execution_finish_time": "2023-07-10T18:52:34.5546688Z",
              "spark_jobs": null,
              "parent_msg_id": "0b442c54-a8e3-4e1b-ba1f-bf3f0f47cd4b"
            },
            "text/plain": "StatementMeta(spark3p3sm, 47, 10, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# canvas assignment learning resource data\r\n",
        "source_directory = 'stage2/Refined/canvas/v2.0/general/assignments'\r\n",
        "dfAssgn = oea.load(source_directory)\r\n",
        "dfAssgn = dfAssgn.select(['id', 'title', 'context_id', 'unlock_at', 'lock_at'])\r\n",
        "\r\n",
        "# map course id to SIS course id\r\n",
        "source_directory = 'stage2/Refined/canvas/v2.0/general/courses'\r\n",
        "dfCourse = oea.load(source_directory)\r\n",
        "dfCourse = dfCourse.select(['id','sis_source_id'])\r\n",
        "dfCourse = dfCourse.withColumnRenamed(\"id\", \"context_id\")\r\n",
        "dfAssgn = dfAssgn.join(dfCourse, \"context_id\")\r\n",
        "dfAssgn = dfAssgn.drop(\"context_id\")\r\n",
        "dfAssgn = dfAssgn.withColumnRenamed(\"sis_source_id\", \"category\")\r\n",
        "\r\n",
        "# get instructor id\r\n",
        "dfAssgn = dfAssgn.join(dfInstructor, \"category\")\r\n",
        "\r\n",
        "# map to schema columns\r\n",
        "column_mapping = {'id': 'source_resource_id', 'category': 'course_id','grader_pseudonym': 'instructor_id', 'title': 'name', 'unlock_at': 'time_open', \r\n",
        "                'lock_at': 'time_close'}\r\n",
        "dfSource = format_to_schema(dfAssgn, column_mapping, dfDimResource.schema, source_directory)           \r\n",
        "\r\n",
        "dfSource = dfSource.withColumn(\"resource_type\", lit(\"assignment\"))\r\n",
        "dfSource = dfSource.select(dfDimResource.columns) # ensure column order matches\r\n",
        "\r\n",
        "dfDimResource = dfDimResource.union(dfSource)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "47",
              "statement_id": 13,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-07-10T18:55:21.5003354Z",
              "session_start_time": null,
              "execution_start_time": "2023-07-10T18:55:21.6442647Z",
              "execution_finish_time": "2023-07-10T18:55:22.2167738Z",
              "spark_jobs": null,
              "parent_msg_id": "ba1dbff8-b2d4-41ad-91df-13820e5dca56"
            },
            "text/plain": "StatementMeta(spark3p3sm, 47, 13, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# canvas quiz learning resource data\r\n",
        "source_directory = 'stage2/Refined/canvas/v2.0/general/quizzes'\r\n",
        "dfQuiz = oea.load(source_directory)\r\n",
        "dfQuiz = dfQuiz.select(['id', 'title', 'context_id', 'unlock_at', 'lock_at'])\r\n",
        "\r\n",
        "# map course id to SIS course id\r\n",
        "source_directory = 'stage2/Refined/canvas/v2.0/general/courses'\r\n",
        "dfCourse = oea.load(source_directory)\r\n",
        "dfCourse = dfCourse.select(['id','sis_source_id'])\r\n",
        "dfCourse = dfCourse.withColumnRenamed(\"id\", \"context_id\")\r\n",
        "dfQuiz = dfQuiz.join(dfCourse, \"context_id\")\r\n",
        "dfQuiz = dfQuiz.drop(\"context_id\")\r\n",
        "dfQuiz = dfQuiz.withColumnRenamed(\"sis_source_id\", \"category\")\r\n",
        "\r\n",
        "# get instructor id\r\n",
        "dfQuiz = dfQuiz.join(dfInstructor, \"category\")\r\n",
        "\r\n",
        "# map to schema columns\r\n",
        "column_mapping = {'id': 'source_resource_id', 'category': 'course_id','grader_pseudonym': 'instructor_id', 'title': 'name', 'unlock_at': 'time_open', \r\n",
        "                'lock_at': 'time_close'}\r\n",
        "dfSource = format_to_schema(dfQuiz, column_mapping, dfDimResource.schema, source_directory)           \r\n",
        "\r\n",
        "dfSource = dfSource.withColumn(\"resource_type\", lit(\"quiz\"))\r\n",
        "dfSource = dfSource.select(dfDimResource.columns) # ensure column order matches\r\n",
        "\r\n",
        "dfDimResource = dfDimResource.union(dfSource)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "47",
              "statement_id": 14,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-07-10T18:55:50.6619889Z",
              "session_start_time": null,
              "execution_start_time": "2023-07-10T18:55:50.8175383Z",
              "execution_finish_time": "2023-07-10T18:55:53.6461671Z",
              "spark_jobs": null,
              "parent_msg_id": "a55ac576-fddb-40ea-b8a9-62f35aa608c1"
            },
            "text/plain": "StatementMeta(spark3p3sm, 47, 14, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate uuid\r\n",
        "uuid_udf = f.udf(lambda : str(uuid.uuid4().hex), StringType())\r\n",
        "dfDimResource = dfDimResource.withColumn('id', uuid_udf())"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "47",
              "statement_id": 15,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-07-10T18:55:57.6709082Z",
              "session_start_time": null,
              "execution_start_time": "2023-07-10T18:55:57.8892229Z",
              "execution_finish_time": "2023-07-10T18:55:58.0528636Z",
              "spark_jobs": null,
              "parent_msg_id": "fd43e287-c799-4c96-a649-4c7041e4727c"
            },
            "text/plain": "StatementMeta(spark3p3sm, 47, 15, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "publish(dfDimResource, 'stage2/Enriched/learning_analytics/v2.0/general/dim_resource', 'stage3/Published/learning_analytics/v2.0/general/dim_resource', primary_key='id')"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "47",
              "statement_id": 17,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-07-10T18:56:13.1414564Z",
              "session_start_time": null,
              "execution_start_time": "2023-07-10T18:56:13.2957926Z",
              "execution_finish_time": "2023-07-10T18:56:42.6782123Z",
              "spark_jobs": null,
              "parent_msg_id": "191359ab-0717-4991-80ad-f4493d3e5f8f"
            },
            "text/plain": "StatementMeta(spark3p3sm, 47, 17, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-10 18:56:41,203 - OEA - INFO - Number of new inbound rows processed: 1321\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 35,
          "data": {
            "text/plain": "1321"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "oea.add_to_lake_db(f'stage3/Published/learning_analytics/v2.0/general/dim_resource')"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "47",
              "statement_id": 18,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-07-10T18:57:04.5841749Z",
              "session_start_time": null,
              "execution_start_time": "2023-07-10T18:57:04.7753213Z",
              "execution_finish_time": "2023-07-10T18:57:15.6781945Z",
              "spark_jobs": null,
              "parent_msg_id": "d19612a1-5011-4277-b882-a076fee16d85"
            },
            "text/plain": "StatementMeta(spark3p3sm, 47, 18, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# oea.rm_if_exists('stage2/Enriched/learning_analytics')\r\n",
        "# oea.rm_if_exists('stage3/Published/learning_analytics')"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "47",
              "statement_id": 16,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-07-10T18:56:04.736318Z",
              "session_start_time": null,
              "execution_start_time": "2023-07-10T18:56:04.8847763Z",
              "execution_finish_time": "2023-07-10T18:56:05.4432227Z",
              "spark_jobs": null,
              "parent_msg_id": "6011add9-632c-4cf3-8a0b-d8a420a3f03b"
            },
            "text/plain": "StatementMeta(spark3p3sm, 47, 16, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}